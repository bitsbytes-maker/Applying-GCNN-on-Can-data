{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph_Classification_pytorch_Fuzzy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn5lP_AIY6Tl",
        "outputId": "81356bae-3404-4f69-90b8-b1e4780163d6"
      },
      "source": [
        "!unzip /content/Fuzzy_dataset.csv.zip\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Fuzzy_dataset.csv.zip\n",
            "  inflating: Fuzzy_dataset.csv       \n",
            "  inflating: __MACOSX/._Fuzzy_dataset.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZCHzwTHV15P"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\r\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.7.0+cu101.html\r\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT5jR_cmeVJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463ba448-3f53-4cf6-afdd-28f5c7a61cc3"
      },
      "source": [
        "import torch\r\n",
        "from torch_geometric.data import Data\r\n",
        "\r\n",
        "edge_index = torch.tensor([[0, 1, 3, 4],\r\n",
        "                           [1, 0, 1, 1]], dtype=torch.long)\r\n",
        "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\r\n",
        "\r\n",
        "data = Data(x=x, edge_index=edge_index.t().contiguous())\r\n",
        "\r\n",
        "print(data['x'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.],\n",
            "        [ 0.],\n",
            "        [ 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQSy-dk-Y2Pr",
        "outputId": "edf9c943-0082-416c-aece-b83556f28646"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "attackFreeArray = []\r\n",
        "file = open('/content/Fuzzy_dataset.csv', 'r')\r\n",
        "attackList = []\r\n",
        "counter = 0\r\n",
        "graphList = []\r\n",
        "ultimateGraphList = [] \r\n",
        "uttimateDetectionList = []\r\n",
        "graphCounter = 0\r\n",
        "\r\n",
        "noOfMessages = 200\r\n",
        "for line in file:\r\n",
        "  Xpartition = line.split()[0].split(',')\r\n",
        "  attackList.append(Xpartition[len(Xpartition)-1])\r\n",
        "\r\n",
        "  \r\n",
        "  node = Xpartition[1]\r\n",
        "\r\n",
        "  graphList.append(node)\r\n",
        "  if len(graphList) == noOfMessages: #No of messages\r\n",
        "    ultimateGraphList.append(graphList)\r\n",
        "    uttimateDetectionList.append(attackList)\r\n",
        "\r\n",
        "  \r\n",
        "    graphCounter+=1    \r\n",
        "    graphList = []\r\n",
        "    attackList = []\r\n",
        "  \r\n",
        "\r\n",
        "ugl = ultimateGraphList\r\n",
        "udl = uttimateDetectionList\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(len(graphList))\r\n",
        "print(len(ugl))\r\n",
        "print(ugl[3])\r\n",
        "print(len(udl))\r\n",
        "print(udl[0])\r\n",
        "\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "19194\n",
            "['0260', '02a0', '0329', '0545', '02b0', '0430', '04b1', '01f1', '0153', '0002', '00a0', '00a1', '02c0', '0350', '0130', '0131', '0140', '0370', '043f', '0440', '0690', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0002', '0153', '0130', '0131', '0140', '0350', '02c0', '0370', '043f', '0440', '04f0', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0430', '04b1', '01f1', '0153', '0002', '0350', '0370', '02c0', '043f', '0130', '0131', '0140', '0440', '0316', '018f', '0260', '02a0', '0329', '0545', '05f0', '02b0', '0002', '0153', '0130', '0131', '0140', '02c0', '0350', '0370', '043f', '0440', '04f0', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0430', '04b1', '01f1', '0153', '0002', '0350', '0370', '02c0', '043f', '0130', '0131', '0140', '0440', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0002', '0153', '0130', '0131', '0140', '02c0', '0350', '0370', '043f', '0440', '04f0', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0430', '04b1', '01f1', '0153', '0002', '0350', '0370', '02c0', '043f', '0130', '0131', '0140', '0440', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0002', '0153', '0130', '0131', '0140', '02c0', '0350', '0370', '043f', '0440', '04f0', '0316', '018f', '0260', '02a0', '0329', '0545', '05f0', '02b0', '0430', '04b1', '01f1', '0153', '0002', '0350', '0370', '02c0', '043f', '0130', '0131', '0140', '0440', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0', '0002', '0153', '0130', '0131', '0140', '02c0', '0350', '0370', '043f', '0440', '04f0', '0316', '018f', '0260', '02a0', '0329', '0545', '02b0']\n",
            "19194\n",
            "['R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL2hk2SDbBuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3d914b-ef2a-410c-cca1-d0d2f386ec06"
      },
      "source": [
        "#Making graph from the 200 sequential of id and store them in a file as Graph adjacent list\r\n",
        "from collections import defaultdict\r\n",
        "import networkx as nx\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "import torch\r\n",
        "from scipy.sparse import csr_matrix\r\n",
        "from torch_geometric.data import Data, DataLoader\r\n",
        "gAttackfree=nx.DiGraph()\r\n",
        "gAttacked = nx.DiGraph()\r\n",
        "\r\n",
        "lenugl = len(ugl)\r\n",
        "\r\n",
        "counter = 0\r\n",
        "gAttackfreeCounter = 0\r\n",
        "gAttackedCounter = 0\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "allLabelList = []\r\n",
        "nodeFeatureList = []\r\n",
        "uvList = []\r\n",
        "DataList = []\r\n",
        "for i in range(0,lenugl):\r\n",
        "  uList = []\r\n",
        "  vList = []\r\n",
        "  attackFree = 0\r\n",
        "  fList = []\r\n",
        "  all_unique_nodes = list(set(ugl[i]))\r\n",
        "  ln = len(all_unique_nodes)\r\n",
        "  array = np.zeros((ln,ln))\r\n",
        "  for j in range (0, len(ugl[i])-1):\r\n",
        "     u = all_unique_nodes.index(ugl[i][j])\r\n",
        "     v = all_unique_nodes.index(ugl[i][j+1])\r\n",
        "     uList.append(u)\r\n",
        "     vList.append(v)\r\n",
        "     array[u][v] = array[u][v]+1\r\n",
        "  uvList.append([uList,vList])\r\n",
        "  edge_index =  torch.LongTensor([uList,vList])\r\n",
        "  \r\n",
        "  for k in range(len(array)):\r\n",
        "    indeg = 0\r\n",
        "    outdeg = 0\r\n",
        "    for l in range(len(array[k])):\r\n",
        "      outdeg = outdeg + array[k][l]\r\n",
        "      indeg = indeg + array[l][k]\r\n",
        "    fList.append([indeg,outdeg])\r\n",
        "  \r\n",
        "  nodeFeatureList.append(fList)\r\n",
        "  x = torch.FloatTensor(fList)\r\n",
        "\r\n",
        "\r\n",
        "  for j in range (0,len(ugl[i])):\r\n",
        "    if udl[i][j] == 'T': \r\n",
        "      attackFree = 1\r\n",
        "      break\r\n",
        "\r\n",
        "  y = attackFree\r\n",
        "  \r\n",
        "  allLabelList.append(attackFree)\r\n",
        "\r\n",
        "  DataList.append(Data(x = x,edge_index=edge_index,y=y))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(uvList[0])\r\n",
        "print(allLabelList.count(0))\r\n",
        "print(allLabelList.count(1))\r\n",
        "\r\n",
        "print(nodeFeatureList[3])\r\n",
        "\r\n",
        "\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 23, 13, 6, 12, 4, 5, 21, 22, 8, 24, 20, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 9, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 4, 5, 21, 12, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 9, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0], [19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 23, 13, 6, 12, 4, 5, 21, 22, 8, 24, 20, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 9, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 4, 5, 21, 12, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4, 5, 21, 6, 12, 22, 8, 24, 1, 2, 10, 18, 3, 15, 14, 9, 19, 16, 17, 7, 0, 11, 6, 22, 8, 12, 4, 5, 21, 24, 2, 10, 18, 3, 15, 14, 19, 11, 0, 4]]\n",
            "12485\n",
            "6709\n",
            "[[10.0, 10.0], [5.0, 5.0], [11.0, 11.0], [10.0, 10.0], [10.0, 10.0], [10.0, 10.0], [10.0, 10.0], [5.0, 5.0], [10.0, 10.0], [2.0, 2.0], [10.0, 10.0], [10.0, 10.0], [10.0, 10.0], [1.0, 1.0], [11.0, 11.0], [11.0, 11.0], [5.0, 5.0], [5.0, 5.0], [10.0, 11.0], [1.0, 1.0], [11.0, 10.0], [10.0, 10.0], [10.0, 10.0], [1.0, 1.0], [10.0, 10.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBY379dXuKKf",
        "outputId": "1425f5da-24fa-4456-bc83-ed341b44a62b"
      },
      "source": [
        "import random \r\n",
        "\r\n",
        "\r\n",
        "torch.manual_seed(12345)\r\n",
        "random.shuffle(DataList)\r\n",
        "\r\n",
        "dataset = DataList\r\n",
        "\r\n",
        "\r\n",
        "train_size = int(lenugl*.70)\r\n",
        "\r\n",
        "#print(int(train_size))\r\n",
        "\r\n",
        "\r\n",
        "train_dataset = dataset[:train_size]\r\n",
        "test_dataset = dataset[train_size:lenugl]\r\n",
        "\r\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\r\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training graphs: 13435\n",
            "Number of test graphs: 5759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqGewkPHutdK",
        "outputId": "81a927fc-a305-49c3-dda5-9554e6334a8f"
      },
      "source": [
        "from torch_geometric.data import DataLoader\r\n",
        "\r\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\r\n",
        "test_loader = DataLoader(test_dataset,batch_size=128, shuffle=False)\r\n",
        "\r\n",
        "for step, data in enumerate(train_loader):\r\n",
        "    print(f'Step {step + 1}:')\r\n",
        "    print('=======')\r\n",
        "    print(f'Number of graphs in the current batch: {data.num_graphs}')\r\n",
        "    print(data)\r\n",
        "    print()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2983], edge_index=[2, 12736], x=[2983, 2], y=[64])\n",
            "\n",
            "Step 2:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3240], edge_index=[2, 12736], x=[3240, 2], y=[64])\n",
            "\n",
            "Step 3:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3206], edge_index=[2, 12736], x=[3206, 2], y=[64])\n",
            "\n",
            "Step 4:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3027], edge_index=[2, 12736], x=[3027, 2], y=[64])\n",
            "\n",
            "Step 5:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3263], edge_index=[2, 12736], x=[3263, 2], y=[64])\n",
            "\n",
            "Step 6:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3340], edge_index=[2, 12736], x=[3340, 2], y=[64])\n",
            "\n",
            "Step 7:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3452], edge_index=[2, 12736], x=[3452, 2], y=[64])\n",
            "\n",
            "Step 8:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3319], edge_index=[2, 12736], x=[3319, 2], y=[64])\n",
            "\n",
            "Step 9:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2806], edge_index=[2, 12736], x=[2806, 2], y=[64])\n",
            "\n",
            "Step 10:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2953], edge_index=[2, 12736], x=[2953, 2], y=[64])\n",
            "\n",
            "Step 11:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2949], edge_index=[2, 12736], x=[2949, 2], y=[64])\n",
            "\n",
            "Step 12:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3078], edge_index=[2, 12736], x=[3078, 2], y=[64])\n",
            "\n",
            "Step 13:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2947], edge_index=[2, 12736], x=[2947, 2], y=[64])\n",
            "\n",
            "Step 14:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3519], edge_index=[2, 12736], x=[3519, 2], y=[64])\n",
            "\n",
            "Step 15:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3147], edge_index=[2, 12736], x=[3147, 2], y=[64])\n",
            "\n",
            "Step 16:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3461], edge_index=[2, 12736], x=[3461, 2], y=[64])\n",
            "\n",
            "Step 17:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3176], edge_index=[2, 12736], x=[3176, 2], y=[64])\n",
            "\n",
            "Step 18:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3308], edge_index=[2, 12736], x=[3308, 2], y=[64])\n",
            "\n",
            "Step 19:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3103], edge_index=[2, 12736], x=[3103, 2], y=[64])\n",
            "\n",
            "Step 20:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3416], edge_index=[2, 12736], x=[3416, 2], y=[64])\n",
            "\n",
            "Step 21:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3228], edge_index=[2, 12736], x=[3228, 2], y=[64])\n",
            "\n",
            "Step 22:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3141], edge_index=[2, 12736], x=[3141, 2], y=[64])\n",
            "\n",
            "Step 23:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2930], edge_index=[2, 12736], x=[2930, 2], y=[64])\n",
            "\n",
            "Step 24:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2703], edge_index=[2, 12736], x=[2703, 2], y=[64])\n",
            "\n",
            "Step 25:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3154], edge_index=[2, 12736], x=[3154, 2], y=[64])\n",
            "\n",
            "Step 26:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2979], edge_index=[2, 12736], x=[2979, 2], y=[64])\n",
            "\n",
            "Step 27:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2864], edge_index=[2, 12736], x=[2864, 2], y=[64])\n",
            "\n",
            "Step 28:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3421], edge_index=[2, 12736], x=[3421, 2], y=[64])\n",
            "\n",
            "Step 29:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3748], edge_index=[2, 12736], x=[3748, 2], y=[64])\n",
            "\n",
            "Step 30:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3135], edge_index=[2, 12736], x=[3135, 2], y=[64])\n",
            "\n",
            "Step 31:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3298], edge_index=[2, 12736], x=[3298, 2], y=[64])\n",
            "\n",
            "Step 32:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3511], edge_index=[2, 12736], x=[3511, 2], y=[64])\n",
            "\n",
            "Step 33:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3700], edge_index=[2, 12736], x=[3700, 2], y=[64])\n",
            "\n",
            "Step 34:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3467], edge_index=[2, 12736], x=[3467, 2], y=[64])\n",
            "\n",
            "Step 35:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3324], edge_index=[2, 12736], x=[3324, 2], y=[64])\n",
            "\n",
            "Step 36:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3225], edge_index=[2, 12736], x=[3225, 2], y=[64])\n",
            "\n",
            "Step 37:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3230], edge_index=[2, 12736], x=[3230, 2], y=[64])\n",
            "\n",
            "Step 38:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2871], edge_index=[2, 12736], x=[2871, 2], y=[64])\n",
            "\n",
            "Step 39:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3370], edge_index=[2, 12736], x=[3370, 2], y=[64])\n",
            "\n",
            "Step 40:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3363], edge_index=[2, 12736], x=[3363, 2], y=[64])\n",
            "\n",
            "Step 41:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2766], edge_index=[2, 12736], x=[2766, 2], y=[64])\n",
            "\n",
            "Step 42:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3071], edge_index=[2, 12736], x=[3071, 2], y=[64])\n",
            "\n",
            "Step 43:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2784], edge_index=[2, 12736], x=[2784, 2], y=[64])\n",
            "\n",
            "Step 44:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3131], edge_index=[2, 12736], x=[3131, 2], y=[64])\n",
            "\n",
            "Step 45:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2672], edge_index=[2, 12736], x=[2672, 2], y=[64])\n",
            "\n",
            "Step 46:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3155], edge_index=[2, 12736], x=[3155, 2], y=[64])\n",
            "\n",
            "Step 47:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3161], edge_index=[2, 12736], x=[3161, 2], y=[64])\n",
            "\n",
            "Step 48:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2658], edge_index=[2, 12736], x=[2658, 2], y=[64])\n",
            "\n",
            "Step 49:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2627], edge_index=[2, 12736], x=[2627, 2], y=[64])\n",
            "\n",
            "Step 50:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3615], edge_index=[2, 12736], x=[3615, 2], y=[64])\n",
            "\n",
            "Step 51:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3052], edge_index=[2, 12736], x=[3052, 2], y=[64])\n",
            "\n",
            "Step 52:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2920], edge_index=[2, 12736], x=[2920, 2], y=[64])\n",
            "\n",
            "Step 53:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3376], edge_index=[2, 12736], x=[3376, 2], y=[64])\n",
            "\n",
            "Step 54:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2777], edge_index=[2, 12736], x=[2777, 2], y=[64])\n",
            "\n",
            "Step 55:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2963], edge_index=[2, 12736], x=[2963, 2], y=[64])\n",
            "\n",
            "Step 56:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2721], edge_index=[2, 12736], x=[2721, 2], y=[64])\n",
            "\n",
            "Step 57:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3445], edge_index=[2, 12736], x=[3445, 2], y=[64])\n",
            "\n",
            "Step 58:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3451], edge_index=[2, 12736], x=[3451, 2], y=[64])\n",
            "\n",
            "Step 59:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3120], edge_index=[2, 12736], x=[3120, 2], y=[64])\n",
            "\n",
            "Step 60:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3438], edge_index=[2, 12736], x=[3438, 2], y=[64])\n",
            "\n",
            "Step 61:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3512], edge_index=[2, 12736], x=[3512, 2], y=[64])\n",
            "\n",
            "Step 62:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2999], edge_index=[2, 12736], x=[2999, 2], y=[64])\n",
            "\n",
            "Step 63:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3118], edge_index=[2, 12736], x=[3118, 2], y=[64])\n",
            "\n",
            "Step 64:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3120], edge_index=[2, 12736], x=[3120, 2], y=[64])\n",
            "\n",
            "Step 65:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2967], edge_index=[2, 12736], x=[2967, 2], y=[64])\n",
            "\n",
            "Step 66:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3411], edge_index=[2, 12736], x=[3411, 2], y=[64])\n",
            "\n",
            "Step 67:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3099], edge_index=[2, 12736], x=[3099, 2], y=[64])\n",
            "\n",
            "Step 68:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3572], edge_index=[2, 12736], x=[3572, 2], y=[64])\n",
            "\n",
            "Step 69:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2834], edge_index=[2, 12736], x=[2834, 2], y=[64])\n",
            "\n",
            "Step 70:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3187], edge_index=[2, 12736], x=[3187, 2], y=[64])\n",
            "\n",
            "Step 71:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3146], edge_index=[2, 12736], x=[3146, 2], y=[64])\n",
            "\n",
            "Step 72:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2695], edge_index=[2, 12736], x=[2695, 2], y=[64])\n",
            "\n",
            "Step 73:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3095], edge_index=[2, 12736], x=[3095, 2], y=[64])\n",
            "\n",
            "Step 74:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2875], edge_index=[2, 12736], x=[2875, 2], y=[64])\n",
            "\n",
            "Step 75:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3163], edge_index=[2, 12736], x=[3163, 2], y=[64])\n",
            "\n",
            "Step 76:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3006], edge_index=[2, 12736], x=[3006, 2], y=[64])\n",
            "\n",
            "Step 77:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3156], edge_index=[2, 12736], x=[3156, 2], y=[64])\n",
            "\n",
            "Step 78:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3374], edge_index=[2, 12736], x=[3374, 2], y=[64])\n",
            "\n",
            "Step 79:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3026], edge_index=[2, 12736], x=[3026, 2], y=[64])\n",
            "\n",
            "Step 80:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2678], edge_index=[2, 12736], x=[2678, 2], y=[64])\n",
            "\n",
            "Step 81:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3466], edge_index=[2, 12736], x=[3466, 2], y=[64])\n",
            "\n",
            "Step 82:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3050], edge_index=[2, 12736], x=[3050, 2], y=[64])\n",
            "\n",
            "Step 83:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3236], edge_index=[2, 12736], x=[3236, 2], y=[64])\n",
            "\n",
            "Step 84:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3466], edge_index=[2, 12736], x=[3466, 2], y=[64])\n",
            "\n",
            "Step 85:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3101], edge_index=[2, 12736], x=[3101, 2], y=[64])\n",
            "\n",
            "Step 86:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3431], edge_index=[2, 12736], x=[3431, 2], y=[64])\n",
            "\n",
            "Step 87:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2849], edge_index=[2, 12736], x=[2849, 2], y=[64])\n",
            "\n",
            "Step 88:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3041], edge_index=[2, 12736], x=[3041, 2], y=[64])\n",
            "\n",
            "Step 89:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3485], edge_index=[2, 12736], x=[3485, 2], y=[64])\n",
            "\n",
            "Step 90:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3208], edge_index=[2, 12736], x=[3208, 2], y=[64])\n",
            "\n",
            "Step 91:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3029], edge_index=[2, 12736], x=[3029, 2], y=[64])\n",
            "\n",
            "Step 92:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3391], edge_index=[2, 12736], x=[3391, 2], y=[64])\n",
            "\n",
            "Step 93:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2889], edge_index=[2, 12736], x=[2889, 2], y=[64])\n",
            "\n",
            "Step 94:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3066], edge_index=[2, 12736], x=[3066, 2], y=[64])\n",
            "\n",
            "Step 95:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2904], edge_index=[2, 12736], x=[2904, 2], y=[64])\n",
            "\n",
            "Step 96:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3287], edge_index=[2, 12736], x=[3287, 2], y=[64])\n",
            "\n",
            "Step 97:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2518], edge_index=[2, 12736], x=[2518, 2], y=[64])\n",
            "\n",
            "Step 98:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2788], edge_index=[2, 12736], x=[2788, 2], y=[64])\n",
            "\n",
            "Step 99:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3444], edge_index=[2, 12736], x=[3444, 2], y=[64])\n",
            "\n",
            "Step 100:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2673], edge_index=[2, 12736], x=[2673, 2], y=[64])\n",
            "\n",
            "Step 101:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3412], edge_index=[2, 12736], x=[3412, 2], y=[64])\n",
            "\n",
            "Step 102:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3020], edge_index=[2, 12736], x=[3020, 2], y=[64])\n",
            "\n",
            "Step 103:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3322], edge_index=[2, 12736], x=[3322, 2], y=[64])\n",
            "\n",
            "Step 104:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2840], edge_index=[2, 12736], x=[2840, 2], y=[64])\n",
            "\n",
            "Step 105:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3415], edge_index=[2, 12736], x=[3415, 2], y=[64])\n",
            "\n",
            "Step 106:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3203], edge_index=[2, 12736], x=[3203, 2], y=[64])\n",
            "\n",
            "Step 107:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2663], edge_index=[2, 12736], x=[2663, 2], y=[64])\n",
            "\n",
            "Step 108:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2932], edge_index=[2, 12736], x=[2932, 2], y=[64])\n",
            "\n",
            "Step 109:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2963], edge_index=[2, 12736], x=[2963, 2], y=[64])\n",
            "\n",
            "Step 110:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2939], edge_index=[2, 12736], x=[2939, 2], y=[64])\n",
            "\n",
            "Step 111:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3371], edge_index=[2, 12736], x=[3371, 2], y=[64])\n",
            "\n",
            "Step 112:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3104], edge_index=[2, 12736], x=[3104, 2], y=[64])\n",
            "\n",
            "Step 113:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2927], edge_index=[2, 12736], x=[2927, 2], y=[64])\n",
            "\n",
            "Step 114:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3215], edge_index=[2, 12736], x=[3215, 2], y=[64])\n",
            "\n",
            "Step 115:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3671], edge_index=[2, 12736], x=[3671, 2], y=[64])\n",
            "\n",
            "Step 116:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2869], edge_index=[2, 12736], x=[2869, 2], y=[64])\n",
            "\n",
            "Step 117:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3060], edge_index=[2, 12736], x=[3060, 2], y=[64])\n",
            "\n",
            "Step 118:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2986], edge_index=[2, 12736], x=[2986, 2], y=[64])\n",
            "\n",
            "Step 119:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2479], edge_index=[2, 12736], x=[2479, 2], y=[64])\n",
            "\n",
            "Step 120:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3511], edge_index=[2, 12736], x=[3511, 2], y=[64])\n",
            "\n",
            "Step 121:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2923], edge_index=[2, 12736], x=[2923, 2], y=[64])\n",
            "\n",
            "Step 122:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3061], edge_index=[2, 12736], x=[3061, 2], y=[64])\n",
            "\n",
            "Step 123:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2632], edge_index=[2, 12736], x=[2632, 2], y=[64])\n",
            "\n",
            "Step 124:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2951], edge_index=[2, 12736], x=[2951, 2], y=[64])\n",
            "\n",
            "Step 125:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3023], edge_index=[2, 12736], x=[3023, 2], y=[64])\n",
            "\n",
            "Step 126:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2718], edge_index=[2, 12736], x=[2718, 2], y=[64])\n",
            "\n",
            "Step 127:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2777], edge_index=[2, 12736], x=[2777, 2], y=[64])\n",
            "\n",
            "Step 128:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2906], edge_index=[2, 12736], x=[2906, 2], y=[64])\n",
            "\n",
            "Step 129:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2447], edge_index=[2, 12736], x=[2447, 2], y=[64])\n",
            "\n",
            "Step 130:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3522], edge_index=[2, 12736], x=[3522, 2], y=[64])\n",
            "\n",
            "Step 131:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3167], edge_index=[2, 12736], x=[3167, 2], y=[64])\n",
            "\n",
            "Step 132:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3096], edge_index=[2, 12736], x=[3096, 2], y=[64])\n",
            "\n",
            "Step 133:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3586], edge_index=[2, 12736], x=[3586, 2], y=[64])\n",
            "\n",
            "Step 134:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3308], edge_index=[2, 12736], x=[3308, 2], y=[64])\n",
            "\n",
            "Step 135:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3573], edge_index=[2, 12736], x=[3573, 2], y=[64])\n",
            "\n",
            "Step 136:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2901], edge_index=[2, 12736], x=[2901, 2], y=[64])\n",
            "\n",
            "Step 137:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2810], edge_index=[2, 12736], x=[2810, 2], y=[64])\n",
            "\n",
            "Step 138:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2960], edge_index=[2, 12736], x=[2960, 2], y=[64])\n",
            "\n",
            "Step 139:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3230], edge_index=[2, 12736], x=[3230, 2], y=[64])\n",
            "\n",
            "Step 140:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3588], edge_index=[2, 12736], x=[3588, 2], y=[64])\n",
            "\n",
            "Step 141:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3157], edge_index=[2, 12736], x=[3157, 2], y=[64])\n",
            "\n",
            "Step 142:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2893], edge_index=[2, 12736], x=[2893, 2], y=[64])\n",
            "\n",
            "Step 143:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3207], edge_index=[2, 12736], x=[3207, 2], y=[64])\n",
            "\n",
            "Step 144:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3204], edge_index=[2, 12736], x=[3204, 2], y=[64])\n",
            "\n",
            "Step 145:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2826], edge_index=[2, 12736], x=[2826, 2], y=[64])\n",
            "\n",
            "Step 146:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3239], edge_index=[2, 12736], x=[3239, 2], y=[64])\n",
            "\n",
            "Step 147:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3400], edge_index=[2, 12736], x=[3400, 2], y=[64])\n",
            "\n",
            "Step 148:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3325], edge_index=[2, 12736], x=[3325, 2], y=[64])\n",
            "\n",
            "Step 149:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2896], edge_index=[2, 12736], x=[2896, 2], y=[64])\n",
            "\n",
            "Step 150:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2990], edge_index=[2, 12736], x=[2990, 2], y=[64])\n",
            "\n",
            "Step 151:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2817], edge_index=[2, 12736], x=[2817, 2], y=[64])\n",
            "\n",
            "Step 152:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2797], edge_index=[2, 12736], x=[2797, 2], y=[64])\n",
            "\n",
            "Step 153:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2968], edge_index=[2, 12736], x=[2968, 2], y=[64])\n",
            "\n",
            "Step 154:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3110], edge_index=[2, 12736], x=[3110, 2], y=[64])\n",
            "\n",
            "Step 155:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3221], edge_index=[2, 12736], x=[3221, 2], y=[64])\n",
            "\n",
            "Step 156:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3028], edge_index=[2, 12736], x=[3028, 2], y=[64])\n",
            "\n",
            "Step 157:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2968], edge_index=[2, 12736], x=[2968, 2], y=[64])\n",
            "\n",
            "Step 158:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3163], edge_index=[2, 12736], x=[3163, 2], y=[64])\n",
            "\n",
            "Step 159:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3149], edge_index=[2, 12736], x=[3149, 2], y=[64])\n",
            "\n",
            "Step 160:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3039], edge_index=[2, 12736], x=[3039, 2], y=[64])\n",
            "\n",
            "Step 161:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2804], edge_index=[2, 12736], x=[2804, 2], y=[64])\n",
            "\n",
            "Step 162:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3176], edge_index=[2, 12736], x=[3176, 2], y=[64])\n",
            "\n",
            "Step 163:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2888], edge_index=[2, 12736], x=[2888, 2], y=[64])\n",
            "\n",
            "Step 164:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3091], edge_index=[2, 12736], x=[3091, 2], y=[64])\n",
            "\n",
            "Step 165:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3466], edge_index=[2, 12736], x=[3466, 2], y=[64])\n",
            "\n",
            "Step 166:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3912], edge_index=[2, 12736], x=[3912, 2], y=[64])\n",
            "\n",
            "Step 167:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3475], edge_index=[2, 12736], x=[3475, 2], y=[64])\n",
            "\n",
            "Step 168:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3174], edge_index=[2, 12736], x=[3174, 2], y=[64])\n",
            "\n",
            "Step 169:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2816], edge_index=[2, 12736], x=[2816, 2], y=[64])\n",
            "\n",
            "Step 170:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3140], edge_index=[2, 12736], x=[3140, 2], y=[64])\n",
            "\n",
            "Step 171:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3163], edge_index=[2, 12736], x=[3163, 2], y=[64])\n",
            "\n",
            "Step 172:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2973], edge_index=[2, 12736], x=[2973, 2], y=[64])\n",
            "\n",
            "Step 173:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2917], edge_index=[2, 12736], x=[2917, 2], y=[64])\n",
            "\n",
            "Step 174:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3375], edge_index=[2, 12736], x=[3375, 2], y=[64])\n",
            "\n",
            "Step 175:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2713], edge_index=[2, 12736], x=[2713, 2], y=[64])\n",
            "\n",
            "Step 176:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2794], edge_index=[2, 12736], x=[2794, 2], y=[64])\n",
            "\n",
            "Step 177:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3346], edge_index=[2, 12736], x=[3346, 2], y=[64])\n",
            "\n",
            "Step 178:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2926], edge_index=[2, 12736], x=[2926, 2], y=[64])\n",
            "\n",
            "Step 179:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2795], edge_index=[2, 12736], x=[2795, 2], y=[64])\n",
            "\n",
            "Step 180:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2922], edge_index=[2, 12736], x=[2922, 2], y=[64])\n",
            "\n",
            "Step 181:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3300], edge_index=[2, 12736], x=[3300, 2], y=[64])\n",
            "\n",
            "Step 182:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3587], edge_index=[2, 12736], x=[3587, 2], y=[64])\n",
            "\n",
            "Step 183:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3306], edge_index=[2, 12736], x=[3306, 2], y=[64])\n",
            "\n",
            "Step 184:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3244], edge_index=[2, 12736], x=[3244, 2], y=[64])\n",
            "\n",
            "Step 185:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2933], edge_index=[2, 12736], x=[2933, 2], y=[64])\n",
            "\n",
            "Step 186:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3628], edge_index=[2, 12736], x=[3628, 2], y=[64])\n",
            "\n",
            "Step 187:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3240], edge_index=[2, 12736], x=[3240, 2], y=[64])\n",
            "\n",
            "Step 188:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2851], edge_index=[2, 12736], x=[2851, 2], y=[64])\n",
            "\n",
            "Step 189:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3178], edge_index=[2, 12736], x=[3178, 2], y=[64])\n",
            "\n",
            "Step 190:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2908], edge_index=[2, 12736], x=[2908, 2], y=[64])\n",
            "\n",
            "Step 191:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3020], edge_index=[2, 12736], x=[3020, 2], y=[64])\n",
            "\n",
            "Step 192:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3600], edge_index=[2, 12736], x=[3600, 2], y=[64])\n",
            "\n",
            "Step 193:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3008], edge_index=[2, 12736], x=[3008, 2], y=[64])\n",
            "\n",
            "Step 194:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3025], edge_index=[2, 12736], x=[3025, 2], y=[64])\n",
            "\n",
            "Step 195:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3298], edge_index=[2, 12736], x=[3298, 2], y=[64])\n",
            "\n",
            "Step 196:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3492], edge_index=[2, 12736], x=[3492, 2], y=[64])\n",
            "\n",
            "Step 197:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[4020], edge_index=[2, 12736], x=[4020, 2], y=[64])\n",
            "\n",
            "Step 198:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3326], edge_index=[2, 12736], x=[3326, 2], y=[64])\n",
            "\n",
            "Step 199:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3456], edge_index=[2, 12736], x=[3456, 2], y=[64])\n",
            "\n",
            "Step 200:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2827], edge_index=[2, 12736], x=[2827, 2], y=[64])\n",
            "\n",
            "Step 201:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2819], edge_index=[2, 12736], x=[2819, 2], y=[64])\n",
            "\n",
            "Step 202:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3310], edge_index=[2, 12736], x=[3310, 2], y=[64])\n",
            "\n",
            "Step 203:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3187], edge_index=[2, 12736], x=[3187, 2], y=[64])\n",
            "\n",
            "Step 204:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3084], edge_index=[2, 12736], x=[3084, 2], y=[64])\n",
            "\n",
            "Step 205:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2655], edge_index=[2, 12736], x=[2655, 2], y=[64])\n",
            "\n",
            "Step 206:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3572], edge_index=[2, 12736], x=[3572, 2], y=[64])\n",
            "\n",
            "Step 207:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[2954], edge_index=[2, 12736], x=[2954, 2], y=[64])\n",
            "\n",
            "Step 208:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3040], edge_index=[2, 12736], x=[3040, 2], y=[64])\n",
            "\n",
            "Step 209:\n",
            "=======\n",
            "Number of graphs in the current batch: 64\n",
            "Batch(batch=[3296], edge_index=[2, 12736], x=[3296, 2], y=[64])\n",
            "\n",
            "Step 210:\n",
            "=======\n",
            "Number of graphs in the current batch: 59\n",
            "Batch(batch=[3126], edge_index=[2, 11741], x=[3126, 2], y=[59])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a3c2gh_u-H3",
        "outputId": "ccfd8847-719d-4436-b7e7-e7feb7ae7e8a"
      },
      "source": [
        "from torch.nn import Linear\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch_geometric.nn import GCNConv\r\n",
        "from torch_geometric.nn import global_mean_pool\r\n",
        "\r\n",
        "\r\n",
        "class GCN(torch.nn.Module):\r\n",
        "    def __init__(self, hidden_channels):\r\n",
        "        super(GCN, self).__init__()\r\n",
        "        torch.manual_seed(12345)\r\n",
        "        self.conv1 = GCNConv(2, hidden_channels)\r\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\r\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\r\n",
        "        self.lin = Linear(hidden_channels, 2)\r\n",
        "\r\n",
        "    def forward(self, x, edge_index, batch):\r\n",
        "        # 1. Obtain node embeddings \r\n",
        "        x = self.conv1(x, edge_index)\r\n",
        "        x = x.relu()\r\n",
        "        x = self.conv2(x, edge_index)\r\n",
        "        x = x.relu()\r\n",
        "        x = self.conv3(x, edge_index)\r\n",
        "\r\n",
        "        # 2. Readout layer\r\n",
        "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\r\n",
        "\r\n",
        "        # 3. Apply a final classifier\r\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\r\n",
        "        x = self.lin(x)\r\n",
        "        \r\n",
        "        return x\r\n",
        "\r\n",
        "model = GCN(hidden_channels=64)\r\n",
        "print(model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(2, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "0XUA8MPFvqgY",
        "outputId": "d7e5a656-081d-4d7b-f056-b1d4208ec3b1"
      },
      "source": [
        "from IPython.display import Javascript\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\r\n",
        "\r\n",
        "model = GCN(hidden_channels=64)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\r\n",
        "criterion = torch.nn.CrossEntropyLoss()\r\n",
        "yTrue = []\r\n",
        "yPred = []\r\n",
        "\r\n",
        "def train():\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    for data in train_loader:  # Iterate in batches over the training dataset.\r\n",
        "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\r\n",
        "         loss = criterion(out, data.y)  # Compute the loss.\r\n",
        "         loss.backward()  # Derive gradients.\r\n",
        "         optimizer.step()  # Update parameters based on gradients.\r\n",
        "         optimizer.zero_grad()  # Clear gradients.\r\n",
        "\r\n",
        "def test(loader):\r\n",
        "     model.eval()\r\n",
        "\r\n",
        "     correct = 0\r\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\r\n",
        "         out = model(data.x, data.edge_index, data.batch)  \r\n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\r\n",
        "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\r\n",
        "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\r\n",
        "\r\n",
        "\r\n",
        "kkkk = 11\r\n",
        "for epoch in range(1, kkkk):\r\n",
        "    train()\r\n",
        "    train_acc = test(train_loader)\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, Train Acc: 0.9978\n",
            "Epoch: 002, Train Acc: 0.9967\n",
            "Epoch: 003, Train Acc: 0.9975\n",
            "Epoch: 004, Train Acc: 0.9975\n",
            "Epoch: 005, Train Acc: 0.9964\n",
            "Epoch: 006, Train Acc: 0.9972\n",
            "Epoch: 007, Train Acc: 0.9972\n",
            "Epoch: 008, Train Acc: 0.9978\n",
            "Epoch: 009, Train Acc: 0.9977\n",
            "Epoch: 010, Train Acc: 0.9976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeIN4PHEtwk6",
        "outputId": "997c433d-42a8-4810-af4f-9d2c0134cc75"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "def conf(yTrue,yPred):\r\n",
        "  tp,tn,fp,fn = 0,0,0,0\r\n",
        "  for i in range(len(yTrue)):\r\n",
        "    if yTrue[i] == yPred[i] and yTrue[i] == 1:\r\n",
        "      tn= tn+1\r\n",
        "\r\n",
        "    elif yTrue[i] == yPred[i] and yTrue[i] == 0:\r\n",
        "      tp = tp+1\r\n",
        "    elif yTrue[i] == 0 and yPred[i] == 1:\r\n",
        "      fp=fp+1\r\n",
        "    else:\r\n",
        "      fn=fn+1\r\n",
        "  \r\n",
        "\r\n",
        "  return np.array([[tp,fp],[fn,tn]])\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def test1(loader):\r\n",
        "     model.eval()\r\n",
        "\r\n",
        "     correct = 0\r\n",
        "     cf = np.array([[0,0],[0,0]])\r\n",
        "     for data in loader:  # Iterate in batches over the training/test dataset.\r\n",
        "         out = model(data.x, data.edge_index, data.batch)  \r\n",
        "         pred = out.argmax(dim=1)  # Use the class with highest probability.\r\n",
        "         correct +=(data.y).sum()  # Check against ground-truth labels.\r\n",
        "         c=conf(np.array(data.y),np.array(pred))\r\n",
        "         print(c)\r\n",
        "\r\n",
        "         cf = cf+c\r\n",
        "     print(correct)\r\n",
        "      \r\n",
        "\r\n",
        "     return cf  # Derive ratio of correct predictions.\r\n",
        "\r\n",
        "print('isafhksfh')\r\n",
        "cf = test1(test_loader)  \r\n",
        "\r\n",
        "\r\n",
        "cf = cf.T\r\n",
        "print(cf)\r\n",
        "print((cf[0][0]+cf[1][1])/(cf[0][0]+cf[0][1]+cf[1][0]+cf[1][1]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "isafhksfh\n",
            "[[74  0]\n",
            " [ 0 54]]\n",
            "[[80  0]\n",
            " [ 1 47]]\n",
            "[[90  0]\n",
            " [ 0 38]]\n",
            "[[85  0]\n",
            " [ 1 42]]\n",
            "[[96  0]\n",
            " [ 0 32]]\n",
            "[[76  0]\n",
            " [ 0 52]]\n",
            "[[82  0]\n",
            " [ 0 46]]\n",
            "[[90  0]\n",
            " [ 0 38]]\n",
            "[[86  0]\n",
            " [ 0 42]]\n",
            "[[90  0]\n",
            " [ 0 38]]\n",
            "[[75  0]\n",
            " [ 1 52]]\n",
            "[[88  0]\n",
            " [ 0 40]]\n",
            "[[85  0]\n",
            " [ 1 42]]\n",
            "[[76  0]\n",
            " [ 1 51]]\n",
            "[[85  0]\n",
            " [ 0 43]]\n",
            "[[86  0]\n",
            " [ 0 42]]\n",
            "[[75  0]\n",
            " [ 0 53]]\n",
            "[[69  0]\n",
            " [ 1 58]]\n",
            "[[88  0]\n",
            " [ 0 40]]\n",
            "[[84  0]\n",
            " [ 0 44]]\n",
            "[[83  0]\n",
            " [ 1 44]]\n",
            "[[86  0]\n",
            " [ 0 42]]\n",
            "[[77  0]\n",
            " [ 0 51]]\n",
            "[[85  0]\n",
            " [ 0 43]]\n",
            "[[79  0]\n",
            " [ 0 49]]\n",
            "[[77  0]\n",
            " [ 0 51]]\n",
            "[[87  0]\n",
            " [ 0 41]]\n",
            "[[87  0]\n",
            " [ 0 41]]\n",
            "[[81  0]\n",
            " [ 0 47]]\n",
            "[[87  0]\n",
            " [ 0 41]]\n",
            "[[82  0]\n",
            " [ 1 45]]\n",
            "[[87  0]\n",
            " [ 0 41]]\n",
            "[[79  0]\n",
            " [ 0 49]]\n",
            "[[81  0]\n",
            " [ 1 46]]\n",
            "[[84  0]\n",
            " [ 0 44]]\n",
            "[[82  0]\n",
            " [ 0 46]]\n",
            "[[89  0]\n",
            " [ 0 39]]\n",
            "[[91  0]\n",
            " [ 2 35]]\n",
            "[[82  0]\n",
            " [ 1 45]]\n",
            "[[82  0]\n",
            " [ 1 45]]\n",
            "[[85  0]\n",
            " [ 0 43]]\n",
            "[[92  0]\n",
            " [ 0 36]]\n",
            "[[74  0]\n",
            " [ 1 53]]\n",
            "[[91  0]\n",
            " [ 0 37]]\n",
            "[[78  0]\n",
            " [ 0 49]]\n",
            "tensor(2011)\n",
            "[[3748   14]\n",
            " [   0 1997]]\n",
            "0.9975690223997222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "RDk3R1ruC9Np",
        "outputId": "717f60eb-5de0-4910-f19f-d700ec7ddd12"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "cm = cf\r\n",
        "\r\n",
        "\r\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=[\"Attack free\",\"Fuzzy attacks\"], \r\n",
        "                                 index=[\"Attack free\",\"Fuzzy attacks\"])\r\n",
        "sns.set(font_scale=2.0)\r\n",
        "sns.heatmap(cm_matrix, annot=True, fmt= 'g', cmap='YlGnBu')\r\n",
        "plt.rcParams['font.size'] = 3\r\n",
        "plt.rcParams['figure.figsize'] = (3, 3)  \r\n",
        "# plt.title(\"Confusion Matrix for All attack\")\r\n",
        "plt.xlabel(\"Actual label\")\r\n",
        "plt.ylabel(\"Predicted label\")\r\n",
        "plt.yticks(rotation = 45)\r\n",
        "plt.xticks(rotation = 45, ha = 'right')\r\n",
        " \r\n",
        "plt.savefig('confusion_fuzzy.pdf', bbox_inches = \"tight\")\r\n",
        "# plt.savefig('confusion_fuzzy.svg', bbox_inches = \"tight\")\r\n",
        "# plt.savefig('confusion_fuzzy.png', bbox_inches = \"tight\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRjqeizxuGSz",
        "outputId": "411c2a33-eefa-42e4-f5b7-7756e9c4f93b"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "import time\r\n",
        "import argparse\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "from torch.nn.parameter import Parameter\r\n",
        "from torch.nn.modules.module import Module\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class GraphConvolution(Module):\r\n",
        "\r\n",
        "    def __init__(self, in_features, out_features, bias=True):\r\n",
        "        super(GraphConvolution, self).__init__()\r\n",
        "        \r\n",
        "        # print(in_features)\r\n",
        "        # print(out_features)\r\n",
        "        self.in_features = in_features\r\n",
        "        self.out_features = out_features\r\n",
        "        self.weight = Parameter(torch.DoubleTensor(in_features, out_features))\r\n",
        "        if bias:\r\n",
        "            self.bias = Parameter(torch.DoubleTensor(out_features))\r\n",
        "        else:\r\n",
        "            self.register_parameter('bias', None)\r\n",
        "        self.reset_parameters()\r\n",
        "    \r\n",
        "    def reset_parameters(self):\r\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\r\n",
        "        self.weight.data.uniform_(-stdv, stdv)\r\n",
        "        if self.bias is not None:\r\n",
        "            self.bias.data.uniform_(-stdv, stdv)\r\n",
        "\r\n",
        "    def forward(self, input, adj):\r\n",
        "        support = torch.matmul(input, self.weight)\r\n",
        "        output = torch.matmul(adj, support)\r\n",
        "        if self.bias is not None:\r\n",
        "            return output + self.bias\r\n",
        "        else:\r\n",
        "            return output\r\n",
        "\r\n",
        "    def __repr__(self):\r\n",
        "        return self.__class__.__name__ + ' (' \\\r\n",
        "               + str(self.in_features) + ' -> ' \\\r\n",
        "               + str(self.out_features) + ')'\r\n",
        "\r\n",
        "class GCN(nn.Module):\r\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout):\r\n",
        "        super(GCN, self).__init__()\r\n",
        "\r\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\r\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\r\n",
        "        self.dropout = dropout\r\n",
        "\r\n",
        "    def forward(self, x, adj):\r\n",
        "        x = F.relu(self.gc1(x, adj))\r\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\r\n",
        "        x = self.gc2(x, adj)\r\n",
        "        #print(F.log_softmax(x, dim=1))\r\n",
        "        return F.log_softmax(x, dim=1)\r\n",
        "\r\n",
        "\r\n",
        "seed = 42\r\n",
        "epochs = 200\r\n",
        "lr = 0.01\r\n",
        "weight_decay = 5e-4\r\n",
        "hidden = 16\r\n",
        "dropout =0.5\r\n",
        "np.random.seed(seed)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "adj, features, labels = aList, nList, lList\r\n",
        "\r\n",
        "#adj, features, labels = aList[, nList, lList\r\n",
        "\r\n",
        "f = int(lenugl*.7)\r\n",
        "g = int(lenugl*.15)\r\n",
        "h = int(lenugl*.15)\r\n",
        "\r\n",
        "print(f)\r\n",
        "print(g)\r\n",
        "print(h)\r\n",
        "\r\n",
        "idx_train = torch.LongTensor(range(f))\r\n",
        "idx_test = torch.LongTensor(range(f,f+g))\r\n",
        "idx_val = torch.LongTensor(range(f+g,f+g+h))\r\n",
        "\r\n",
        "# Model and optimizer\r\n",
        "print(features.shape)\r\n",
        "model = GCN(nfeat=features.shape[1],\r\n",
        "            nhid=hidden,\r\n",
        "            nclass=labels.max().item() + 1,\r\n",
        "            dropout=dropout)\r\n",
        "#print(model)\r\n",
        "optimizer = optim.Adam(model.parameters(),\r\n",
        "                       lr=lr, weight_decay=weight_decay)\r\n",
        "\r\n",
        "\r\n",
        "fastmode = False\r\n",
        "\r\n",
        "\r\n",
        "def accuracy(output, labels, t = 0):\r\n",
        "    preds = output.max(1)[1].type_as(labels)\r\n",
        "    if t == 1:\r\n",
        "\r\n",
        "      print(np.array(confusion_matrix(list(labels),list(preds))).T)\r\n",
        "    correct = preds.eq(labels).double()\r\n",
        "    correct = correct.sum()\r\n",
        "    return correct / len(labels)\r\n",
        "\r\n",
        "def train(epoch):\r\n",
        "    t = time.time()\r\n",
        "    model.train()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    #print(features.shape)\r\n",
        "    output = model(features, adj)\r\n",
        "    # print(output.shape)\r\n",
        "    # print(output[idx_train].shape)\r\n",
        "    # print(labels[idx_train].shape)\r\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\r\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\r\n",
        "    loss_train.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    if not fastmode:\r\n",
        "        # Evaluate validation set performance separately,\r\n",
        "        # deactivates dropout during validation run.\r\n",
        "        model.eval()\r\n",
        "        #print(features.shape)\r\n",
        "        #print(model)\r\n",
        "        output = model(features, adj)\r\n",
        "\r\n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\r\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\r\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\r\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\r\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\r\n",
        "          'loss_val: {:.4f}'.format(loss_val.item()),\r\n",
        "          'acc_val: {:.4f}'.format(acc_val.item()),\r\n",
        "          'time: {:.4f}s'.format(time.time() - t))\r\n",
        "\r\n",
        "\r\n",
        "def test(t=0):\r\n",
        "    model.eval()\r\n",
        "    output = model(features, adj)\r\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\r\n",
        "    \r\n",
        "    acc_test= accuracy(output[idx_test], labels[idx_test],t)\r\n",
        "    \r\n",
        "    print(\"Test set results:\",\r\n",
        "          \"loss= {:.4f}\".format(loss_test.item()),\r\n",
        "          \"accuracy= {:.4f}\".format(acc_test.item()))\r\n",
        "    \r\n",
        "\r\n",
        "\r\n",
        "# Train model\r\n",
        "t_total = time.time()\r\n",
        "for epoch in range(epochs):\r\n",
        "    train(epoch)\r\n",
        "print(\"Optimization Finished!\")\r\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\r\n",
        "\r\n",
        "# Testing\r\n",
        "t_total = time.time()\r\n",
        "test(1)\r\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12829\n",
            "2749\n",
            "2749\n",
            "torch.Size([18328, 11])\n",
            "Epoch: 0001 loss_train: 7.6337 acc_train: 0.4098 loss_val: 6.3732 acc_val: 0.0000 time: 3.1980s\n",
            "Epoch: 0002 loss_train: 6.1403 acc_train: 0.4537 loss_val: 3.6720 acc_val: 0.0004 time: 3.2029s\n",
            "Epoch: 0003 loss_train: 5.2571 acc_train: 0.4728 loss_val: 1.6822 acc_val: 0.0266 time: 3.2154s\n",
            "Epoch: 0004 loss_train: 4.3784 acc_train: 0.4959 loss_val: 0.7081 acc_val: 0.6257 time: 3.2163s\n",
            "Epoch: 0005 loss_train: 3.7808 acc_train: 0.5108 loss_val: 0.3234 acc_val: 0.9251 time: 3.2138s\n",
            "Epoch: 0006 loss_train: 3.1041 acc_train: 0.5385 loss_val: 0.1696 acc_val: 0.9825 time: 3.2134s\n",
            "Epoch: 0007 loss_train: 2.4855 acc_train: 0.5926 loss_val: 0.0965 acc_val: 0.9956 time: 3.2264s\n",
            "Epoch: 0008 loss_train: 1.9026 acc_train: 0.6389 loss_val: 0.0577 acc_val: 0.9996 time: 3.2210s\n",
            "Epoch: 0009 loss_train: 1.5366 acc_train: 0.6977 loss_val: 0.0386 acc_val: 1.0000 time: 3.2166s\n",
            "Epoch: 0010 loss_train: 1.2613 acc_train: 0.7397 loss_val: 0.0468 acc_val: 1.0000 time: 3.2610s\n",
            "Epoch: 0011 loss_train: 1.0972 acc_train: 0.7656 loss_val: 0.0734 acc_val: 1.0000 time: 3.2887s\n",
            "Epoch: 0012 loss_train: 0.9655 acc_train: 0.7664 loss_val: 0.1126 acc_val: 1.0000 time: 3.2086s\n",
            "Epoch: 0013 loss_train: 0.8745 acc_train: 0.7872 loss_val: 0.1574 acc_val: 1.0000 time: 3.2382s\n",
            "Epoch: 0014 loss_train: 0.8406 acc_train: 0.7870 loss_val: 0.1946 acc_val: 1.0000 time: 3.2419s\n",
            "Epoch: 0015 loss_train: 0.7501 acc_train: 0.7786 loss_val: 0.2196 acc_val: 1.0000 time: 3.2437s\n",
            "Epoch: 0016 loss_train: 0.7015 acc_train: 0.7782 loss_val: 0.2370 acc_val: 1.0000 time: 3.2407s\n",
            "Epoch: 0017 loss_train: 0.6254 acc_train: 0.7722 loss_val: 0.2513 acc_val: 1.0000 time: 3.2323s\n",
            "Epoch: 0018 loss_train: 0.5726 acc_train: 0.7650 loss_val: 0.2661 acc_val: 1.0000 time: 3.2024s\n",
            "Epoch: 0019 loss_train: 0.5421 acc_train: 0.7552 loss_val: 0.2857 acc_val: 1.0000 time: 3.2051s\n",
            "Epoch: 0020 loss_train: 0.5835 acc_train: 0.7355 loss_val: 0.3146 acc_val: 1.0000 time: 3.2045s\n",
            "Epoch: 0021 loss_train: 0.5221 acc_train: 0.7831 loss_val: 0.3609 acc_val: 1.0000 time: 3.2259s\n",
            "Epoch: 0022 loss_train: 0.5209 acc_train: 0.7815 loss_val: 0.4118 acc_val: 1.0000 time: 3.2017s\n",
            "Epoch: 0023 loss_train: 0.5152 acc_train: 0.7998 loss_val: 0.4544 acc_val: 1.0000 time: 3.2102s\n",
            "Epoch: 0024 loss_train: 0.5142 acc_train: 0.8303 loss_val: 0.4830 acc_val: 1.0000 time: 3.2234s\n",
            "Epoch: 0025 loss_train: 0.5180 acc_train: 0.7825 loss_val: 0.4871 acc_val: 1.0000 time: 3.2256s\n",
            "Epoch: 0026 loss_train: 0.5234 acc_train: 0.7814 loss_val: 0.4586 acc_val: 1.0000 time: 3.2245s\n",
            "Epoch: 0027 loss_train: 0.5149 acc_train: 0.7863 loss_val: 0.4151 acc_val: 1.0000 time: 3.2124s\n",
            "Epoch: 0028 loss_train: 0.5125 acc_train: 0.8380 loss_val: 0.3656 acc_val: 1.0000 time: 3.2253s\n",
            "Epoch: 0029 loss_train: 0.4928 acc_train: 0.8400 loss_val: 0.3060 acc_val: 1.0000 time: 3.2112s\n",
            "Epoch: 0030 loss_train: 0.4764 acc_train: 0.8383 loss_val: 0.2640 acc_val: 1.0000 time: 3.1861s\n",
            "Epoch: 0031 loss_train: 0.4664 acc_train: 0.8408 loss_val: 0.2371 acc_val: 1.0000 time: 3.2087s\n",
            "Epoch: 0032 loss_train: 0.4483 acc_train: 0.8537 loss_val: 0.2218 acc_val: 1.0000 time: 3.1896s\n",
            "Epoch: 0033 loss_train: 0.4334 acc_train: 0.8630 loss_val: 0.2106 acc_val: 1.0000 time: 3.1860s\n",
            "Epoch: 0034 loss_train: 0.4230 acc_train: 0.8624 loss_val: 0.2015 acc_val: 1.0000 time: 3.2028s\n",
            "Epoch: 0035 loss_train: 0.4184 acc_train: 0.8637 loss_val: 0.1904 acc_val: 1.0000 time: 3.2433s\n",
            "Epoch: 0036 loss_train: 0.4104 acc_train: 0.8633 loss_val: 0.1768 acc_val: 1.0000 time: 3.2030s\n",
            "Epoch: 0037 loss_train: 0.4155 acc_train: 0.8552 loss_val: 0.1617 acc_val: 1.0000 time: 3.1930s\n",
            "Epoch: 0038 loss_train: 0.4140 acc_train: 0.8518 loss_val: 0.1463 acc_val: 1.0000 time: 3.2109s\n",
            "Epoch: 0039 loss_train: 0.4114 acc_train: 0.8505 loss_val: 0.1317 acc_val: 1.0000 time: 3.2056s\n",
            "Epoch: 0040 loss_train: 0.4157 acc_train: 0.8499 loss_val: 0.1198 acc_val: 1.0000 time: 3.1971s\n",
            "Epoch: 0041 loss_train: 0.4106 acc_train: 0.8556 loss_val: 0.1105 acc_val: 1.0000 time: 3.2042s\n",
            "Epoch: 0042 loss_train: 0.4065 acc_train: 0.8589 loss_val: 0.1048 acc_val: 1.0000 time: 3.1843s\n",
            "Epoch: 0043 loss_train: 0.4014 acc_train: 0.8616 loss_val: 0.1023 acc_val: 1.0000 time: 3.1936s\n",
            "Epoch: 0044 loss_train: 0.3982 acc_train: 0.8637 loss_val: 0.1028 acc_val: 1.0000 time: 3.2277s\n",
            "Epoch: 0045 loss_train: 0.4007 acc_train: 0.8602 loss_val: 0.1053 acc_val: 1.0000 time: 3.2102s\n",
            "Epoch: 0046 loss_train: 0.4084 acc_train: 0.8596 loss_val: 0.1097 acc_val: 1.0000 time: 3.2258s\n",
            "Epoch: 0047 loss_train: 0.3986 acc_train: 0.8641 loss_val: 0.1150 acc_val: 1.0000 time: 3.2149s\n",
            "Epoch: 0048 loss_train: 0.4045 acc_train: 0.8595 loss_val: 0.1198 acc_val: 1.0000 time: 3.2103s\n",
            "Epoch: 0049 loss_train: 0.3966 acc_train: 0.8604 loss_val: 0.1239 acc_val: 1.0000 time: 3.2134s\n",
            "Epoch: 0050 loss_train: 0.3855 acc_train: 0.8630 loss_val: 0.1244 acc_val: 1.0000 time: 3.2146s\n",
            "Epoch: 0051 loss_train: 0.3878 acc_train: 0.8616 loss_val: 0.1217 acc_val: 1.0000 time: 3.2268s\n",
            "Epoch: 0052 loss_train: 0.3924 acc_train: 0.8583 loss_val: 0.1181 acc_val: 1.0000 time: 3.2159s\n",
            "Epoch: 0053 loss_train: 0.3960 acc_train: 0.8570 loss_val: 0.1150 acc_val: 1.0000 time: 3.2110s\n",
            "Epoch: 0054 loss_train: 0.3856 acc_train: 0.8606 loss_val: 0.1137 acc_val: 1.0000 time: 3.2416s\n",
            "Epoch: 0055 loss_train: 0.3872 acc_train: 0.8628 loss_val: 0.1145 acc_val: 1.0000 time: 3.2236s\n",
            "Epoch: 0056 loss_train: 0.3844 acc_train: 0.8619 loss_val: 0.1169 acc_val: 1.0000 time: 3.2058s\n",
            "Epoch: 0057 loss_train: 0.3864 acc_train: 0.8633 loss_val: 0.1214 acc_val: 1.0000 time: 3.1880s\n",
            "Epoch: 0058 loss_train: 0.3871 acc_train: 0.8630 loss_val: 0.1274 acc_val: 1.0000 time: 3.1767s\n",
            "Epoch: 0059 loss_train: 0.3849 acc_train: 0.8635 loss_val: 0.1304 acc_val: 1.0000 time: 3.1653s\n",
            "Epoch: 0060 loss_train: 0.3878 acc_train: 0.8635 loss_val: 0.1318 acc_val: 1.0000 time: 3.1839s\n",
            "Epoch: 0061 loss_train: 0.3837 acc_train: 0.8636 loss_val: 0.1298 acc_val: 1.0000 time: 3.1740s\n",
            "Epoch: 0062 loss_train: 0.3842 acc_train: 0.8630 loss_val: 0.1236 acc_val: 1.0000 time: 3.2018s\n",
            "Epoch: 0063 loss_train: 0.3760 acc_train: 0.8643 loss_val: 0.1148 acc_val: 1.0000 time: 3.2399s\n",
            "Epoch: 0064 loss_train: 0.3836 acc_train: 0.8632 loss_val: 0.1089 acc_val: 1.0000 time: 3.2779s\n",
            "Epoch: 0065 loss_train: 0.3807 acc_train: 0.8608 loss_val: 0.1054 acc_val: 1.0000 time: 3.2439s\n",
            "Epoch: 0066 loss_train: 0.3844 acc_train: 0.8618 loss_val: 0.1068 acc_val: 1.0000 time: 3.2122s\n",
            "Epoch: 0067 loss_train: 0.3755 acc_train: 0.8655 loss_val: 0.1101 acc_val: 1.0000 time: 3.2138s\n",
            "Epoch: 0068 loss_train: 0.3771 acc_train: 0.8666 loss_val: 0.1139 acc_val: 1.0000 time: 3.2340s\n",
            "Epoch: 0069 loss_train: 0.3819 acc_train: 0.8657 loss_val: 0.1166 acc_val: 1.0000 time: 3.2114s\n",
            "Epoch: 0070 loss_train: 0.3762 acc_train: 0.8659 loss_val: 0.1153 acc_val: 1.0000 time: 3.2154s\n",
            "Epoch: 0071 loss_train: 0.3716 acc_train: 0.8675 loss_val: 0.1106 acc_val: 1.0000 time: 3.1969s\n",
            "Epoch: 0072 loss_train: 0.3809 acc_train: 0.8633 loss_val: 0.1046 acc_val: 1.0000 time: 3.2137s\n",
            "Epoch: 0073 loss_train: 0.3797 acc_train: 0.8663 loss_val: 0.0989 acc_val: 1.0000 time: 3.2144s\n",
            "Epoch: 0074 loss_train: 0.3793 acc_train: 0.8635 loss_val: 0.0951 acc_val: 1.0000 time: 3.2193s\n",
            "Epoch: 0075 loss_train: 0.3746 acc_train: 0.8641 loss_val: 0.0951 acc_val: 1.0000 time: 3.2200s\n",
            "Epoch: 0076 loss_train: 0.3779 acc_train: 0.8645 loss_val: 0.0967 acc_val: 1.0000 time: 3.2207s\n",
            "Epoch: 0077 loss_train: 0.3793 acc_train: 0.8651 loss_val: 0.0988 acc_val: 1.0000 time: 3.8769s\n",
            "Epoch: 0078 loss_train: 0.3719 acc_train: 0.8666 loss_val: 0.1011 acc_val: 1.0000 time: 3.8890s\n",
            "Epoch: 0079 loss_train: 0.3782 acc_train: 0.8646 loss_val: 0.1026 acc_val: 1.0000 time: 3.1795s\n",
            "Epoch: 0080 loss_train: 0.3778 acc_train: 0.8639 loss_val: 0.1019 acc_val: 1.0000 time: 3.1929s\n",
            "Epoch: 0081 loss_train: 0.3738 acc_train: 0.8639 loss_val: 0.0992 acc_val: 1.0000 time: 3.1960s\n",
            "Epoch: 0082 loss_train: 0.3772 acc_train: 0.8637 loss_val: 0.0974 acc_val: 1.0000 time: 3.1857s\n",
            "Epoch: 0083 loss_train: 0.3759 acc_train: 0.8613 loss_val: 0.0970 acc_val: 1.0000 time: 3.4921s\n",
            "Epoch: 0084 loss_train: 0.3718 acc_train: 0.8651 loss_val: 0.0967 acc_val: 1.0000 time: 3.4219s\n",
            "Epoch: 0085 loss_train: 0.3702 acc_train: 0.8657 loss_val: 0.0972 acc_val: 1.0000 time: 3.7369s\n",
            "Epoch: 0086 loss_train: 0.3728 acc_train: 0.8677 loss_val: 0.0974 acc_val: 1.0000 time: 3.3185s\n",
            "Epoch: 0087 loss_train: 0.3733 acc_train: 0.8649 loss_val: 0.0993 acc_val: 1.0000 time: 3.5114s\n",
            "Epoch: 0088 loss_train: 0.3735 acc_train: 0.8651 loss_val: 0.1013 acc_val: 1.0000 time: 3.2337s\n",
            "Epoch: 0089 loss_train: 0.3774 acc_train: 0.8674 loss_val: 0.1039 acc_val: 1.0000 time: 3.2657s\n",
            "Epoch: 0090 loss_train: 0.3766 acc_train: 0.8643 loss_val: 0.1034 acc_val: 1.0000 time: 3.3368s\n",
            "Epoch: 0091 loss_train: 0.3680 acc_train: 0.8697 loss_val: 0.1020 acc_val: 1.0000 time: 3.2910s\n",
            "Epoch: 0092 loss_train: 0.3759 acc_train: 0.8648 loss_val: 0.1002 acc_val: 1.0000 time: 3.2607s\n",
            "Epoch: 0093 loss_train: 0.3711 acc_train: 0.8685 loss_val: 0.0997 acc_val: 1.0000 time: 3.2650s\n",
            "Epoch: 0094 loss_train: 0.3742 acc_train: 0.8661 loss_val: 0.1003 acc_val: 1.0000 time: 3.2202s\n",
            "Epoch: 0095 loss_train: 0.3746 acc_train: 0.8641 loss_val: 0.1015 acc_val: 1.0000 time: 3.2590s\n",
            "Epoch: 0096 loss_train: 0.3718 acc_train: 0.8659 loss_val: 0.1018 acc_val: 1.0000 time: 3.2375s\n",
            "Epoch: 0097 loss_train: 0.3696 acc_train: 0.8655 loss_val: 0.1022 acc_val: 1.0000 time: 3.2272s\n",
            "Epoch: 0098 loss_train: 0.3751 acc_train: 0.8644 loss_val: 0.1033 acc_val: 1.0000 time: 3.2187s\n",
            "Epoch: 0099 loss_train: 0.3698 acc_train: 0.8691 loss_val: 0.1034 acc_val: 1.0000 time: 3.2358s\n",
            "Epoch: 0100 loss_train: 0.3795 acc_train: 0.8647 loss_val: 0.1025 acc_val: 1.0000 time: 3.2179s\n",
            "Epoch: 0101 loss_train: 0.3706 acc_train: 0.8669 loss_val: 0.1001 acc_val: 1.0000 time: 3.2531s\n",
            "Epoch: 0102 loss_train: 0.3670 acc_train: 0.8648 loss_val: 0.0975 acc_val: 1.0000 time: 3.2576s\n",
            "Epoch: 0103 loss_train: 0.3706 acc_train: 0.8650 loss_val: 0.0971 acc_val: 1.0000 time: 3.2381s\n",
            "Epoch: 0104 loss_train: 0.3695 acc_train: 0.8625 loss_val: 0.0968 acc_val: 1.0000 time: 3.2002s\n",
            "Epoch: 0105 loss_train: 0.3675 acc_train: 0.8676 loss_val: 0.0977 acc_val: 1.0000 time: 3.1775s\n",
            "Epoch: 0106 loss_train: 0.3679 acc_train: 0.8659 loss_val: 0.0987 acc_val: 1.0000 time: 3.1678s\n",
            "Epoch: 0107 loss_train: 0.3732 acc_train: 0.8668 loss_val: 0.0996 acc_val: 1.0000 time: 3.2334s\n",
            "Epoch: 0108 loss_train: 0.3745 acc_train: 0.8650 loss_val: 0.0991 acc_val: 1.0000 time: 3.2220s\n",
            "Epoch: 0109 loss_train: 0.3701 acc_train: 0.8686 loss_val: 0.0985 acc_val: 1.0000 time: 3.2400s\n",
            "Epoch: 0110 loss_train: 0.3739 acc_train: 0.8649 loss_val: 0.0989 acc_val: 1.0000 time: 3.2242s\n",
            "Epoch: 0111 loss_train: 0.3710 acc_train: 0.8652 loss_val: 0.0995 acc_val: 1.0000 time: 3.2312s\n",
            "Epoch: 0112 loss_train: 0.3714 acc_train: 0.8651 loss_val: 0.0997 acc_val: 1.0000 time: 3.2138s\n",
            "Epoch: 0113 loss_train: 0.3686 acc_train: 0.8676 loss_val: 0.1003 acc_val: 1.0000 time: 3.2530s\n",
            "Epoch: 0114 loss_train: 0.3734 acc_train: 0.8640 loss_val: 0.0994 acc_val: 1.0000 time: 3.2100s\n",
            "Epoch: 0115 loss_train: 0.3704 acc_train: 0.8669 loss_val: 0.0998 acc_val: 1.0000 time: 3.2092s\n",
            "Epoch: 0116 loss_train: 0.3723 acc_train: 0.8662 loss_val: 0.0994 acc_val: 1.0000 time: 3.1973s\n",
            "Epoch: 0117 loss_train: 0.3700 acc_train: 0.8656 loss_val: 0.0995 acc_val: 1.0000 time: 3.2344s\n",
            "Epoch: 0118 loss_train: 0.3722 acc_train: 0.8659 loss_val: 0.1005 acc_val: 1.0000 time: 3.2229s\n",
            "Epoch: 0119 loss_train: 0.3644 acc_train: 0.8692 loss_val: 0.1010 acc_val: 1.0000 time: 3.2357s\n",
            "Epoch: 0120 loss_train: 0.3716 acc_train: 0.8669 loss_val: 0.1014 acc_val: 1.0000 time: 3.2304s\n",
            "Epoch: 0121 loss_train: 0.3681 acc_train: 0.8687 loss_val: 0.1019 acc_val: 1.0000 time: 3.2611s\n",
            "Epoch: 0122 loss_train: 0.3687 acc_train: 0.8661 loss_val: 0.1011 acc_val: 1.0000 time: 3.2190s\n",
            "Epoch: 0123 loss_train: 0.3695 acc_train: 0.8693 loss_val: 0.1005 acc_val: 1.0000 time: 3.2386s\n",
            "Epoch: 0124 loss_train: 0.3706 acc_train: 0.8652 loss_val: 0.0988 acc_val: 1.0000 time: 3.5511s\n",
            "Epoch: 0125 loss_train: 0.3701 acc_train: 0.8660 loss_val: 0.0980 acc_val: 1.0000 time: 3.2309s\n",
            "Epoch: 0126 loss_train: 0.3696 acc_train: 0.8654 loss_val: 0.0981 acc_val: 1.0000 time: 3.2247s\n",
            "Epoch: 0127 loss_train: 0.3650 acc_train: 0.8680 loss_val: 0.0999 acc_val: 1.0000 time: 3.2440s\n",
            "Epoch: 0128 loss_train: 0.3693 acc_train: 0.8627 loss_val: 0.1008 acc_val: 1.0000 time: 3.2084s\n",
            "Epoch: 0129 loss_train: 0.3655 acc_train: 0.8687 loss_val: 0.0995 acc_val: 1.0000 time: 3.1914s\n",
            "Epoch: 0130 loss_train: 0.3720 acc_train: 0.8641 loss_val: 0.0993 acc_val: 1.0000 time: 3.2051s\n",
            "Epoch: 0131 loss_train: 0.3691 acc_train: 0.8643 loss_val: 0.0969 acc_val: 1.0000 time: 3.2087s\n",
            "Epoch: 0132 loss_train: 0.3696 acc_train: 0.8697 loss_val: 0.0964 acc_val: 1.0000 time: 3.2195s\n",
            "Epoch: 0133 loss_train: 0.3659 acc_train: 0.8697 loss_val: 0.0968 acc_val: 1.0000 time: 3.2363s\n",
            "Epoch: 0134 loss_train: 0.3692 acc_train: 0.8680 loss_val: 0.0981 acc_val: 1.0000 time: 3.1977s\n",
            "Epoch: 0135 loss_train: 0.3717 acc_train: 0.8694 loss_val: 0.0998 acc_val: 1.0000 time: 3.2166s\n",
            "Epoch: 0136 loss_train: 0.3710 acc_train: 0.8687 loss_val: 0.1022 acc_val: 1.0000 time: 3.2137s\n",
            "Epoch: 0137 loss_train: 0.3728 acc_train: 0.8659 loss_val: 0.1037 acc_val: 1.0000 time: 3.2232s\n",
            "Epoch: 0138 loss_train: 0.3725 acc_train: 0.8664 loss_val: 0.1038 acc_val: 1.0000 time: 3.2208s\n",
            "Epoch: 0139 loss_train: 0.3683 acc_train: 0.8703 loss_val: 0.1020 acc_val: 1.0000 time: 3.2061s\n",
            "Epoch: 0140 loss_train: 0.3655 acc_train: 0.8662 loss_val: 0.1004 acc_val: 1.0000 time: 3.1903s\n",
            "Epoch: 0141 loss_train: 0.3732 acc_train: 0.8652 loss_val: 0.1000 acc_val: 1.0000 time: 3.1749s\n",
            "Epoch: 0142 loss_train: 0.3686 acc_train: 0.8668 loss_val: 0.0994 acc_val: 1.0000 time: 3.1867s\n",
            "Epoch: 0143 loss_train: 0.3711 acc_train: 0.8632 loss_val: 0.0994 acc_val: 1.0000 time: 3.2098s\n",
            "Epoch: 0144 loss_train: 0.3653 acc_train: 0.8662 loss_val: 0.0986 acc_val: 1.0000 time: 3.2235s\n",
            "Epoch: 0145 loss_train: 0.3687 acc_train: 0.8673 loss_val: 0.0988 acc_val: 1.0000 time: 3.2359s\n",
            "Epoch: 0146 loss_train: 0.3635 acc_train: 0.8697 loss_val: 0.0971 acc_val: 1.0000 time: 3.2127s\n",
            "Epoch: 0147 loss_train: 0.3738 acc_train: 0.8654 loss_val: 0.0951 acc_val: 1.0000 time: 3.1674s\n",
            "Epoch: 0148 loss_train: 0.3659 acc_train: 0.8651 loss_val: 0.0931 acc_val: 1.0000 time: 3.1630s\n",
            "Epoch: 0149 loss_train: 0.3639 acc_train: 0.8685 loss_val: 0.0920 acc_val: 1.0000 time: 3.1895s\n",
            "Epoch: 0150 loss_train: 0.3675 acc_train: 0.8653 loss_val: 0.0910 acc_val: 1.0000 time: 3.1742s\n",
            "Epoch: 0151 loss_train: 0.3663 acc_train: 0.8712 loss_val: 0.0912 acc_val: 1.0000 time: 3.1990s\n",
            "Epoch: 0152 loss_train: 0.3676 acc_train: 0.8669 loss_val: 0.0925 acc_val: 1.0000 time: 3.1880s\n",
            "Epoch: 0153 loss_train: 0.3647 acc_train: 0.8648 loss_val: 0.0941 acc_val: 1.0000 time: 3.1918s\n",
            "Epoch: 0154 loss_train: 0.3613 acc_train: 0.8701 loss_val: 0.0942 acc_val: 1.0000 time: 3.1655s\n",
            "Epoch: 0155 loss_train: 0.3672 acc_train: 0.8666 loss_val: 0.0936 acc_val: 1.0000 time: 3.1547s\n",
            "Epoch: 0156 loss_train: 0.3684 acc_train: 0.8676 loss_val: 0.0956 acc_val: 1.0000 time: 3.1510s\n",
            "Epoch: 0157 loss_train: 0.3687 acc_train: 0.8669 loss_val: 0.0984 acc_val: 1.0000 time: 3.1646s\n",
            "Epoch: 0158 loss_train: 0.3627 acc_train: 0.8683 loss_val: 0.0994 acc_val: 1.0000 time: 3.1818s\n",
            "Epoch: 0159 loss_train: 0.3662 acc_train: 0.8679 loss_val: 0.0994 acc_val: 1.0000 time: 3.1598s\n",
            "Epoch: 0160 loss_train: 0.3627 acc_train: 0.8698 loss_val: 0.0997 acc_val: 1.0000 time: 3.1691s\n",
            "Epoch: 0161 loss_train: 0.3728 acc_train: 0.8665 loss_val: 0.0982 acc_val: 1.0000 time: 3.2076s\n",
            "Epoch: 0162 loss_train: 0.3673 acc_train: 0.8694 loss_val: 0.0980 acc_val: 1.0000 time: 3.1911s\n",
            "Epoch: 0163 loss_train: 0.3620 acc_train: 0.8704 loss_val: 0.0972 acc_val: 1.0000 time: 3.1588s\n",
            "Epoch: 0164 loss_train: 0.3709 acc_train: 0.8670 loss_val: 0.0963 acc_val: 1.0000 time: 3.1738s\n",
            "Epoch: 0165 loss_train: 0.3705 acc_train: 0.8676 loss_val: 0.0955 acc_val: 1.0000 time: 3.1866s\n",
            "Epoch: 0166 loss_train: 0.3644 acc_train: 0.8681 loss_val: 0.0937 acc_val: 1.0000 time: 3.1494s\n",
            "Epoch: 0167 loss_train: 0.3647 acc_train: 0.8725 loss_val: 0.0938 acc_val: 1.0000 time: 3.1423s\n",
            "Epoch: 0168 loss_train: 0.3630 acc_train: 0.8700 loss_val: 0.0934 acc_val: 1.0000 time: 3.1435s\n",
            "Epoch: 0169 loss_train: 0.3693 acc_train: 0.8687 loss_val: 0.0958 acc_val: 1.0000 time: 3.1504s\n",
            "Epoch: 0170 loss_train: 0.3646 acc_train: 0.8686 loss_val: 0.0971 acc_val: 1.0000 time: 3.1431s\n",
            "Epoch: 0171 loss_train: 0.3652 acc_train: 0.8661 loss_val: 0.0962 acc_val: 1.0000 time: 3.1530s\n",
            "Epoch: 0172 loss_train: 0.3729 acc_train: 0.8660 loss_val: 0.0954 acc_val: 1.0000 time: 3.1567s\n",
            "Epoch: 0173 loss_train: 0.3629 acc_train: 0.8707 loss_val: 0.0940 acc_val: 1.0000 time: 3.1383s\n",
            "Epoch: 0174 loss_train: 0.3648 acc_train: 0.8689 loss_val: 0.0930 acc_val: 1.0000 time: 3.1453s\n",
            "Epoch: 0175 loss_train: 0.3675 acc_train: 0.8634 loss_val: 0.0911 acc_val: 1.0000 time: 3.1253s\n",
            "Epoch: 0176 loss_train: 0.3637 acc_train: 0.8700 loss_val: 0.0908 acc_val: 1.0000 time: 3.1280s\n",
            "Epoch: 0177 loss_train: 0.3612 acc_train: 0.8721 loss_val: 0.0915 acc_val: 1.0000 time: 3.1580s\n",
            "Epoch: 0178 loss_train: 0.3666 acc_train: 0.8666 loss_val: 0.0953 acc_val: 1.0000 time: 3.1350s\n",
            "Epoch: 0179 loss_train: 0.3643 acc_train: 0.8701 loss_val: 0.0974 acc_val: 1.0000 time: 3.1310s\n",
            "Epoch: 0180 loss_train: 0.3659 acc_train: 0.8686 loss_val: 0.0963 acc_val: 1.0000 time: 3.1490s\n",
            "Epoch: 0181 loss_train: 0.3745 acc_train: 0.8655 loss_val: 0.0942 acc_val: 1.0000 time: 3.1517s\n",
            "Epoch: 0182 loss_train: 0.3687 acc_train: 0.8672 loss_val: 0.0927 acc_val: 1.0000 time: 3.1555s\n",
            "Epoch: 0183 loss_train: 0.3637 acc_train: 0.8666 loss_val: 0.0916 acc_val: 1.0000 time: 3.1468s\n",
            "Epoch: 0184 loss_train: 0.3642 acc_train: 0.8686 loss_val: 0.0924 acc_val: 1.0000 time: 3.1617s\n",
            "Epoch: 0185 loss_train: 0.3664 acc_train: 0.8690 loss_val: 0.0944 acc_val: 1.0000 time: 3.1549s\n",
            "Epoch: 0186 loss_train: 0.3659 acc_train: 0.8692 loss_val: 0.0967 acc_val: 1.0000 time: 3.1184s\n",
            "Epoch: 0187 loss_train: 0.3641 acc_train: 0.8688 loss_val: 0.0975 acc_val: 1.0000 time: 3.1303s\n",
            "Epoch: 0188 loss_train: 0.3693 acc_train: 0.8634 loss_val: 0.0953 acc_val: 1.0000 time: 3.1274s\n",
            "Epoch: 0189 loss_train: 0.3650 acc_train: 0.8662 loss_val: 0.0923 acc_val: 1.0000 time: 3.1411s\n",
            "Epoch: 0190 loss_train: 0.3689 acc_train: 0.8673 loss_val: 0.0920 acc_val: 1.0000 time: 3.1227s\n",
            "Epoch: 0191 loss_train: 0.3671 acc_train: 0.8668 loss_val: 0.0935 acc_val: 1.0000 time: 3.1400s\n",
            "Epoch: 0192 loss_train: 0.3646 acc_train: 0.8668 loss_val: 0.0949 acc_val: 1.0000 time: 3.1692s\n",
            "Epoch: 0193 loss_train: 0.3623 acc_train: 0.8661 loss_val: 0.0935 acc_val: 1.0000 time: 3.1431s\n",
            "Epoch: 0194 loss_train: 0.3647 acc_train: 0.8664 loss_val: 0.0914 acc_val: 1.0000 time: 3.1305s\n",
            "Epoch: 0195 loss_train: 0.3667 acc_train: 0.8686 loss_val: 0.0931 acc_val: 1.0000 time: 3.1427s\n",
            "Epoch: 0196 loss_train: 0.3702 acc_train: 0.8681 loss_val: 0.0951 acc_val: 1.0000 time: 3.1281s\n",
            "Epoch: 0197 loss_train: 0.3619 acc_train: 0.8659 loss_val: 0.0960 acc_val: 1.0000 time: 3.1478s\n",
            "Epoch: 0198 loss_train: 0.3643 acc_train: 0.8682 loss_val: 0.0953 acc_val: 1.0000 time: 3.1464s\n",
            "Epoch: 0199 loss_train: 0.3693 acc_train: 0.8700 loss_val: 0.0951 acc_val: 1.0000 time: 3.1338s\n",
            "Epoch: 0200 loss_train: 0.3618 acc_train: 0.8685 loss_val: 0.0931 acc_val: 1.0000 time: 3.1267s\n",
            "Optimization Finished!\n",
            "Total time elapsed: 643.4834s\n",
            "[[2516   30]\n",
            " [  25  178]]\n",
            "Test set results: loss= 0.1356 accuracy= 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywbC84h1ocZt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL3zHj-OdxEl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADUpFHcgjMNb",
        "outputId": "61965dc1-dd50-4ee1-8ed4-9cb8e564f3a0"
      },
      "source": [
        "# cm = [[1612 ,  10],\r\n",
        "#  [   5  ,793]]\r\n",
        "\r\n",
        "\r\n",
        "tp = cm[0][0]\r\n",
        "tn = cm[1][1]\r\n",
        "fp = cm[0][1]\r\n",
        "fn = cm[1][0]\r\n",
        "\r\n",
        "re = tp/(tp+fn)\r\n",
        "pr = tp/(tp+fp)\r\n",
        "f1 = 2*pr*re/(pr+re)\r\n",
        "fpr = fp / (fp+tn)\r\n",
        "print(\"pr..........\"+str(pr))\r\n",
        "print(\"re----\"+str(re))\r\n",
        "\r\n",
        "print(\"f1====\"+str(f1))\r\n",
        "print(\"fpr=====\"+ str(fpr))\r\n",
        "print((tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pr..........0.98989898989899\n",
            "re----0.9932432432432432\n",
            "f1====0.9915682967959528\n",
            "fpr=====0.009708737864077669\n",
            "0.9917355371900827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VzjsHAmdVip"
      },
      "source": [
        "71002\r\n",
        "170939\r\n",
        "0.991287131986724\r\n",
        "[[170760   1929]\r\n",
        " [   179  69073]]\r\n",
        " 5\r\n",
        "\r\n",
        "35791\r\n",
        "85180\r\n",
        "0.9906010531449686\r\n",
        "[[84065    22]\r\n",
        " [ 1115 35769]]\r\n",
        " 10\r\n",
        "\r\n",
        "\r\n",
        "3659\r\n",
        "8438\r\n",
        "0.9962800694387038\r\n",
        "[[8424   31]\r\n",
        " [  14 3628]]\r\n",
        "100\r\n",
        "\r\n",
        "\r\n",
        "1832\r\n",
        "4217\r\n",
        "0.993387336749876\r\n",
        "[[4197   20]\r\n",
        " [  20 1812]]\r\n",
        "\r\n",
        "803\r\n",
        "1617\r\n",
        "0.993801652892562\r\n",
        "[[1612   10]\r\n",
        " [   5  793]]\r\n",
        " 500\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " 464\r\n",
        "746\r\n",
        "0.9917355371900827\r\n",
        "[[743   7]\r\n",
        " [  3 457]]\r\n",
        " 1000\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " 309\r\n",
        "296\r\n",
        "0.9917355371900827\r\n",
        "[[294   3]\r\n",
        " [  2 306]]\r\n",
        " 2k\r\n",
        "\r\n",
        " 175\r\n",
        "67\r\n",
        "1.0\r\n",
        "[[ 67   0]\r\n",
        " [  0 175]]\r\n",
        " 5k\r\n",
        "\r\n",
        "\r\n",
        " 88\r\n",
        "33\r\n",
        "1.0\r\n",
        "[[33  0]\r\n",
        " [ 0 88]]\r\n",
        " 10k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHamcJHRhK4v",
        "outputId": "2b348763-344a-4fe6-ac5b-c1e3103ecf19"
      },
      "source": [
        "cm =[ [[170760 ,  1929],\r\n",
        " [179 , 69073]],\r\n",
        "\r\n",
        " [[84065   , 22],\r\n",
        " [ 1115, 35769]],\r\n",
        "\r\n",
        "[[8424 ,  31],\r\n",
        " [  14, 3628]],\r\n",
        "\r\n",
        " [[4197 ,  20],\r\n",
        " [  20 ,1812]],\r\n",
        "\r\n",
        " [[1612  , 10],\r\n",
        " [   5  ,793]],\r\n",
        "\r\n",
        "[[743 ,  7],\r\n",
        " [  3 ,457]],\r\n",
        "\r\n",
        "\r\n",
        " [[ 67 ,  0],\r\n",
        " [  0 ,175]],\r\n",
        "\r\n",
        " [[33,  0],\r\n",
        " [ 0, 88]]\r\n",
        "]\r\n",
        "\r\n",
        "for i in range(len(cm)):\r\n",
        "\r\n",
        "  tp = cm[i][0][0]\r\n",
        "  tn = cm[i][1][1]\r\n",
        "  fp = cm[i][0][1]\r\n",
        "  fn = cm[i][1][0]\r\n",
        "\r\n",
        "  re = tp/(tp+fn)\r\n",
        "  pr = tp/(tp+fp)\r\n",
        "  f1 = 2*pr*re/(pr+re)\r\n",
        "  fpr = fp / (fp+tn)\r\n",
        "\r\n",
        "\r\n",
        "  mcc = (tp*tn-fp*fn)/((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**.5\r\n",
        "\r\n",
        "  fdr = fp/(fp+tp)\r\n",
        "\r\n",
        "  # print(\"pr..........\"+str(pr))\r\n",
        "  # print(\"re----\"+str(re))\r\n",
        "\r\n",
        "  # print(\"f1====\"+str(f1))\r\n",
        "  # print(\"fpr=====\"+ str(fpr))\r\n",
        "  print(\"mcccccc--------->\" +str(mcc))\r\n",
        "  #print(\"fdr=======\"+str(fdr))\r\n",
        "  # print((tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mcccccc--------->0.9789880325873227\n",
            "mcccccc--------->0.9778659028555149\n",
            "mcccccc--------->0.991178167512607\n",
            "mcccccc--------->0.9843402613459972\n",
            "mcccccc--------->0.9860106010676708\n",
            "mcccccc--------->0.9825172905181248\n",
            "mcccccc--------->1.0\n",
            "mcccccc--------->1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "IgnxX6jBzGlE",
        "outputId": "7b734a8c-891a-40de-adb4-1a2d32e1e196"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "square_node_data = pd.DataFrame(\r\n",
        "    {\"x\": [1, 2, 3, 4], \"y\": [-0.2, 0.3, 0.0, -0.5]}, index=[\"a\", \"b\", \"c\", \"d\"]\r\n",
        ")\r\n",
        "square_node_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b</th>\n",
              "      <td>2</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>d</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x    y\n",
              "a  1 -0.2\n",
              "b  2  0.3\n",
              "c  3  0.0\n",
              "d  4 -0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjpyr1sP1eYU",
        "outputId": "53543534-c8e0-419f-8bac-104ad91da910"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Nodes  Edges  ...  MaximumPagerank  MininumPagerank\n",
            "No.                 ...                                  \n",
            "1        27    112  ...         0.215139         0.011104\n",
            "2        25     75  ...         0.359649         0.018228\n",
            "3        25     88  ...         0.285778         0.015716\n",
            "4        27     97  ...         0.276848         0.014271\n",
            "5        27    137  ...         0.173902         0.013195\n",
            "...     ...    ...  ...              ...              ...\n",
            "1828     26     70  ...         0.077329         0.013768\n",
            "1829     26     73  ...         0.073358         0.011842\n",
            "1830     26     78  ...         0.067820         0.011954\n",
            "1831     26     85  ...         0.071132         0.009662\n",
            "1832     26     76  ...         0.086512         0.008505\n",
            "\n",
            "[1832 rows x 9 columns]\n",
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 1832, Edges: 0\n",
            "\n",
            " Node types:\n",
            "  default: [1832]\n",
            "    Features: float32 vector, length 9\n",
            "    Edge types: none\n",
            "\n",
            " Edge types:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuWQexkI5342"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}